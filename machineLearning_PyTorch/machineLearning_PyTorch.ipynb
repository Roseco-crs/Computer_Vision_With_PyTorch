{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "- Install necessary PyTorch libraries\n",
    "- Use PyTorch to build, train, and evaluate neural networks\n",
    "- Save the trained model parameters and use them later for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0mB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:45\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m611.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/crs/10Academy/computer_Vision_With_PyTorch/venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m527.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cusolver-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m620.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting triton==2.3.1\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m530.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m597.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m593.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pillow-10.3.0 sympy-1.12.1 torch-2.3.1 torchvision-0.18.1 triton-2.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Steps during this project\n",
    "\n",
    "1. Download the MNIST dataset and create a DataLoader for the dataset\n",
    "2. Define an AI model to recognize a hand written digit.\n",
    "3. Train the defined AI model using training data from the MNIST dataset \n",
    "4. Test the trained AI model using testing data from the MNIST dataset\n",
    "5. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the MNIST dataset and create a DataLoader for the dataset\n",
    "\n",
    "The images are 28x28 pixel images of digits 0 through 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 60032\n",
      "Test data size: 10048\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Downloade training data from MNIST datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# create data loaders to iterate over data\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print(f\"Training data size: {len(train_dataloader)*batch_size}\")\n",
    "print(f\"Test data size: {len(test_dataloader)*batch_size}\")\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model\n",
    "\n",
    "- Determine the best device for performing training\n",
    "- Define the AI model as a neural network with 3 layers. We use a ReLU activation function between the layers\n",
    "- Flatten the input by using the Flatten module before passing the input into our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usinig cpu device.\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get device for training\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()     # Apple Silicon GPU\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Usinig {device} device.\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, image_tensor):\n",
    "        image_tensor = self.flatten(image_tensor)\n",
    "        logits = self.linear_relu_stack(image_tensor)\n",
    "        return logits\n",
    "    \n",
    "input_size = 28*28\n",
    "hidden_size = 512\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traing loop\n",
    "\n",
    "We implement a training function to use with train_dataloader to train our AI model. Each iteration over the dataloader returns a batch_size image data tensor along with the expected output. After moving the tensors to the device, we call the foward pass of our model, compute the prediction error using the expected output and then call the backwards pass to compute the gradients and apply them to the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our learning rate, loss function and optimizer\n",
    "learning_rate = 1e-3 \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Let's define our training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # forward pass to compute prediction\n",
    "        pred = model(X)\n",
    "        # Compute prediction error using loss function\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Bacward pass\n",
    "        optimizer.zero_grad()   # zero any previous gradient calculations\n",
    "        loss.backward()         # calculate gradient\n",
    "        optimizer.step()        # update model parameters\n",
    "\n",
    "        if batch_num > 0 and batch_num % 100 == 0 :\n",
    "            loss, current = loss.item(), batch_num*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loop\n",
    "\n",
    "The test methods evaluates the model's predictive performance using the test_dataloader. During testing, we don't require gradient computation, so we set the model in evaluate mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our test function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "\n",
    "Now that we have defined methods to train our model and test the trained model's predictive behavior, let's train the model for 5 epochs over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "------------------------------\n",
      "loss: 0.261721  [ 6400/60000]\n",
      "loss: 0.191323  [12800/60000]\n",
      "loss: 0.271078  [19200/60000]\n",
      "loss: 0.154089  [25600/60000]\n",
      "loss: 0.333872  [32000/60000]\n",
      "loss: 0.115945  [38400/60000]\n",
      "loss: 0.237084  [44800/60000]\n",
      "loss: 0.279653  [51200/60000]\n",
      "loss: 0.199239  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.133410 \n",
      "\n",
      "Epoch 2 \n",
      "------------------------------\n",
      "loss: 0.100302  [ 6400/60000]\n",
      "loss: 0.119812  [12800/60000]\n",
      "loss: 0.102287  [19200/60000]\n",
      "loss: 0.051650  [25600/60000]\n",
      "loss: 0.118045  [32000/60000]\n",
      "loss: 0.056371  [38400/60000]\n",
      "loss: 0.125799  [44800/60000]\n",
      "loss: 0.157174  [51200/60000]\n",
      "loss: 0.103986  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.108690 \n",
      "\n",
      "Epoch 3 \n",
      "------------------------------\n",
      "loss: 0.086614  [ 6400/60000]\n",
      "loss: 0.026222  [12800/60000]\n",
      "loss: 0.063804  [19200/60000]\n",
      "loss: 0.072565  [25600/60000]\n",
      "loss: 0.056617  [32000/60000]\n",
      "loss: 0.027191  [38400/60000]\n",
      "loss: 0.053343  [44800/60000]\n",
      "loss: 0.075020  [51200/60000]\n",
      "loss: 0.078940  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.095802 \n",
      "\n",
      "Epoch 4 \n",
      "------------------------------\n",
      "loss: 0.028264  [ 6400/60000]\n",
      "loss: 0.021184  [12800/60000]\n",
      "loss: 0.021889  [19200/60000]\n",
      "loss: 0.071037  [25600/60000]\n",
      "loss: 0.011758  [32000/60000]\n",
      "loss: 0.038411  [38400/60000]\n",
      "loss: 0.050847  [44800/60000]\n",
      "loss: 0.092713  [51200/60000]\n",
      "loss: 0.092339  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.106613 \n",
      "\n",
      "Epoch 5 \n",
      "------------------------------\n",
      "loss: 0.022774  [ 6400/60000]\n",
      "loss: 0.034020  [12800/60000]\n",
      "loss: 0.040195  [19200/60000]\n",
      "loss: 0.021044  [25600/60000]\n",
      "loss: 0.025435  [32000/60000]\n",
      "loss: 0.017868  [38400/60000]\n",
      "loss: 0.012060  [44800/60000]\n",
      "loss: 0.069657  [51200/60000]\n",
      "loss: 0.028358  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.283859 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Let's run training\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} \\n------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model and make predictions\n",
    "\n",
    "Once we have a trained model, we can save the model parameters for future use in inferences. Here, we save the state_dict of the model which contains the trained parameters. We then create a new instance of the model and load the previously saved parameters into the new instance of the model. Finally, we can inference using the new instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to machineLearning_with_pytorch_model.pth\n",
      "Predicted: \"7\", Actual: \"7\" \n",
      "Predicted: \"2\", Actual: \"2\" \n",
      "Predicted: \"1\", Actual: \"1\" \n",
      "Predicted: \"0\", Actual: \"0\" \n",
      "Predicted: \"4\", Actual: \"4\" \n",
      "Predicted: \"1\", Actual: \"1\" \n",
      "Predicted: \"4\", Actual: \"4\" \n",
      "Predicted: \"9\", Actual: \"9\" \n",
      "Predicted: \"5\", Actual: \"5\" \n",
      "Predicted: \"9\", Actual: \"9\" \n"
     ]
    }
   ],
   "source": [
    "# Save our model parameters\n",
    "torch.save(model.state_dict(), \"machineLearning_with_pytorch_model.pth\")\n",
    "print(\"Saved PyTorch Model State to machineLearning_with_pytorch_model.pth\")\n",
    "\n",
    "# Load the saved model parameters into a new instance of the model\n",
    "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"machineLearning_with_pytorch_model.pth\"))\n",
    "\n",
    "# inference using the new model instance\n",
    "model.eval()\n",
    "for i in range(10):\n",
    "    x, y = test_data[i][0], test_data[i][1]\n",
    "\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = pred[0].argmax(0).item(), y\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\" ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.__dict__\n",
    "# type(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
